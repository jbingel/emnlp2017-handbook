SubmissionNumber#=%=#36
FinalPaperTitle#=%=#Exploiting Linguistic Resources for Neural Machine Translation Using Multi-task Learning
ShortPaperTitle#=%=#Exploiting Linguistic Resources for Neural Machine Translation Using Multi-task Learning
NumberOfPages#=%=#10
CopyrightSigned#=%=#Jan Niehues
JobTitle#==#
Organization#==#KIT
Adenauerring 2
76131 Karlsruhe
Abstract#==#Linguistic resources such as part-of-speech (POS) tags have been extensively
used in statistical machine translation (SMT) frameworks and have yielded
better performances. 
However, usage of such linguistic annotations in neural machine translation
(NMT) systems has been left under-explored. 

In this work, we show that multi-task learning is a successful and a easy
approach to introduce an additional knowledge into an end-to-end neural
attentional model. 
By jointly training several natural language processing (NLP) tasks in one
system, we are able to leverage common information and improve the performance
of the individual task. 

We analyze the impact of three design decisions in multi-task learning: the
tasks used in training, the training schedule, and the degree of parameter
sharing across the tasks, which is defined by the network architecture. 
The experiments are conducted for an German to English translation task. 
As additional linguistic resources, we exploit POS information and
named-entities (NE). 
Experiments show that the translation quality can be improved by up to 1.5 BLEU
points under the low-resource condition. 
The performance of the POS tagger is also improved using the multi-task
learning scheme.
Author{1}{Firstname}#=%=#Jan
Author{1}{Lastname}#=%=#Niehues
Author{1}{Email}#=%=#jan.niehues@kit.edu
Author{1}{Affiliation}#=%=#Karlsruhe Institute of Technology
Author{2}{Firstname}#=%=#Eunah
Author{2}{Lastname}#=%=#Cho
Author{2}{Email}#=%=#eunah.cho@kit.edu
Author{2}{Affiliation}#=%=#Karlsruhe Institute of Technology

==========